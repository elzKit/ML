{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Boosting is a highly successful method, very useful in practice. More than half of the competition-winning methods (Kaggle, etc.) use boosting.\n",
    "\n",
    "Boosting is a particular case of **ensemble** meta-algorithm. Ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms ( build a strong classifier from multiple weak classifiers).\n",
    "\n",
    "Boosting results in a non-linear classifier.\n",
    "\n",
    "The main principle of boosting: we iteratively build an esemble classifier by focusing on the data that was misclassfied in the previous iteration. Concretely: we work with weighted data. We assign higher weights to data points that we misclassified in the previous iteration.\n",
    "\n",
    "## Other types of ensemble methods\n",
    "\n",
    "**Bagging** ( bootstrap aggregating) is another important ensemble method. Here, we train each model in the ensemble using a randomly drawn subset of the training set. Each model in the ensemble votes with equal weight --> we average the prediction.\n",
    "\n",
    "**Random forest** is an example of bagging.\n",
    "\n",
    "\n",
    "## AdaBoost\n",
    "AdaBoost is a particular boosting technique. \n",
    "\n",
    "Principle : \n",
    "\n",
    "1. We add weigths to data points (as usual in boosting)\n",
    "\n",
    "2. We add weights to classifiers. We weigh highly classifiers which either perfrom very well (weighted error close to 0), or very bad (weighted error close to 1) (if inversed, they would be excellent classfiers! - we just assign negative weight to them). We assign a weight close to 0 to classifiers with weighted error close to 0.5 (if the classfier is pretty much random, we don't take it into account).\n",
    "\n",
    "A good explanation of AdaBoost can be found in this paper:\n",
    "    http://rob.schapire.net/papers/explaining-adaboost.pdf\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
